{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to TCore Documentation","text":"<p>TCore is a RISC-V based processor core implementing the RV32IMC instruction set architecture. It is designed to be simple yet configurable, providing a flexible foundation for educational, experimental, and lightweight embedded applications. This documentation will guide you through understanding, configuring, and using TCore effectively.</p>","boost":2},{"location":"#key-features","title":"Key Features","text":"<ul> <li>RISC-V RV32IMC ISA: Supports integer, multiplication/division, and compressed instructions.</li> <li>Configurable Memory System: Optimized for various embedded applications.</li> <li>Pipeline Design: Focused on efficient data processing.</li> <li>UART Support: For communication and debugging.</li> <li>FPGA Friendly: Designed with FPGA implementation in mind.</li> </ul>","boost":2},{"location":"#future-goals","title":"Future Goals","text":"<ul> <li>Adding a branch predictor for performance optimization.</li> <li>Achieving compatibility with official RISC-V International test suites.</li> <li>Implementing machine mode CSR (Control and Status Registers).</li> <li>Providing documentation in both English and Turkish.</li> <li>Supporting open-source ASIC synthesis for low-cost custom designs.</li> </ul>","boost":2},{"location":"#performance-highlights","title":"Performance Highlights","text":"<ul> <li>Core Configurations: Available for RV32I, RV32IC, and RV32IMC.</li> <li>CoreMark/MHz: 2.20 for RV32IMC configuration.</li> <li>Branch Prediction Accuracy: Implements gshare with an 85% accuracy rate.</li> </ul>","boost":2},{"location":"#learn-more","title":"Learn More","text":"<p>Visit the GitHub repository for the source code, implementation details, and contribution guidelines. This documentation will be continually updated as TCore evolves to meet its development goals.</p>","boost":2},{"location":"about/about/","title":"About the Author","text":"<p>Welcome! My name is Kerim Turak, an Electrical and Electronics Engineer specializing in embedded systems, computer architecture, and RISC-V processor design. I am passionate about designing efficient, innovative systems and contributing to open-source projects that push the boundaries of technology.</p>"},{"location":"about/about/#professional-highlights","title":"Professional Highlights:","text":"<ul> <li>Expertise in RISC-V Architecture: Designing parametric memory systems and custom extensions for embedded applications.</li> <li>RTL Design and Verification: Proficient in SystemVerilog and Verilog HDL, focusing on performance-optimized and modular hardware design.</li> <li>Software Skills: Hands-on experience with Python, C, C++, and MATLAB for algorithm development and hardware-software integration.</li> <li>Open-Source Advocate: Actively contributing to and maintaining repositories for collaborative development.</li> </ul>"},{"location":"about/about/#current-focus","title":"Current Focus:","text":"<p>I am currently developing TCore, a fully parametric RISC-V RV32IMC processor core designed to address modern challenges in processor design while remaining adaptable for future innovations. My work involves integrating advanced features like dynamic branch prediction and compressed instruction support.</p> <p>When I am not coding or designing circuits, I enjoy learning about emerging technologies and sharing my knowledge with the community. Feel free to connect with me on LinkedIn or explore my projects on GitHub.</p>"},{"location":"blog/","title":"Blog","text":""},{"location":"design/decode/","title":"Decode Stage Documentation","text":"<p>The Decode Stage in the TCore RISC-V Processor is a critical component responsible for interpreting instructions, extracting operands, and generating control signals. This stage bridges the gap between instruction fetching and execution, ensuring that instructions are properly decoded and prepared for execution.</p>"},{"location":"design/decode/#key-functionalities","title":"Key Functionalities","text":"<ol> <li>Instruction Decoding:</li> <li> <p>Interprets the opcode, function fields (<code>funct3</code>, <code>funct7</code>), and other instruction components to determine the operation type and required actions.</p> </li> <li> <p>Operand Fetching:</p> </li> <li>Retrieves source operands (<code>rs1</code>, <code>rs2</code>) from the register file.</li> <li> <p>Supports data forwarding from writeback to resolve dependencies.</p> </li> <li> <p>Immediate Extraction:</p> </li> <li> <p>Generates immediate values based on instruction type (e.g., I-type, S-type, B-type).</p> </li> <li> <p>Control Signal Generation:</p> </li> <li>Produces control signals required by subsequent pipeline stages (e.g., ALU control, memory access, writeback control).</li> </ol>"},{"location":"design/decode/#module-composition","title":"Module Composition","text":""},{"location":"design/decode/#1-register-file","title":"1. Register File","text":"<ul> <li>Functionality: Stores and provides access to 32 general-purpose registers.</li> </ul>"},{"location":"design/decode/#2-control-unit","title":"2. Control Unit","text":"<ul> <li>Functionality: Decodes the opcode and function fields to generate control signals.</li> </ul>"},{"location":"design/decode/#3-immediate-extension-unit","title":"3. Immediate Extension Unit","text":"<ul> <li>Functionality: Extracts and extends immediate values based on instruction type.</li> </ul>"},{"location":"design/decode/#internal-signals-and-logic","title":"Internal Signals and Logic","text":""},{"location":"design/decode/#forwarding-logic","title":"Forwarding Logic","text":"<ul> <li>Inputs:</li> <li><code>fwd_a_i</code>, <code>fwd_b_i</code>: Forwarding enable signals for source operands.</li> <li><code>wb_data_i</code>: Data forwarded from writeback.</li> <li>Outputs:</li> <li><code>r1_data_o</code>, <code>r2_data_o</code>: Final source operands after forwarding.</li> </ul>"},{"location":"design/decode/#control-signals","title":"Control Signals","text":"<ul> <li><code>alu_in1_sel</code>, <code>alu_in2_sel</code>: Select ALU inputs.</li> <li><code>result_src</code>: Determines the source of the writeback result.</li> <li><code>imm_sel</code>: Specifies the type of immediate to generate.</li> <li><code>pc_sel</code>: Selects the next PC value.</li> <li><code>rf_rw_en</code>, <code>wr_en</code>: Enables register file read/write operations.</li> </ul>"},{"location":"design/execute/","title":"Execution Stage Documentation","text":"<p>The Execution Stage in the TCore RISC-V Processor performs arithmetic and logical operations, branching decisions, and other computations required for instruction execution. This stage is central to the processor's operation, as it produces results based on decoded instructions.</p>"},{"location":"design/execute/#key-functionalities","title":"Key Functionalities","text":"<ol> <li>Arithmetic and Logical Operations:</li> <li> <p>Executes operations like addition, subtraction, bitwise logic, shifts, and comparisons using the ALU.</p> </li> <li> <p>Multiplication and Division:</p> </li> <li>Supports both single-cycle and multi-cycle implementations for multiplication and division.</li> <li> <p>Handles signed and unsigned integer operations.</p> </li> <li> <p>Branch Evaluation:</p> </li> <li>Determines the outcome of branch instructions.</li> <li> <p>Calculates target addresses for jumps and branches.</p> </li> <li> <p>Pipeline Integration:</p> </li> <li>Generates output data and control signals to be passed to subsequent pipeline stages.</li> </ol>"},{"location":"design/execute/#module-composition","title":"Module Composition","text":""},{"location":"design/execute/#1-arithmetic-logic-unit-alu","title":"1. Arithmetic Logic Unit (ALU)","text":"<ul> <li>Functionality: Executes arithmetic, logical, and shift operations.</li> </ul>"},{"location":"design/execute/#2-multiplier-and-divider","title":"2. Multiplier and Divider","text":"<ul> <li>Functionality: Executes multiplication and division operations.</li> <li><code>alu_stall_o</code>: Indicates ongoing multi-cycle operations.</li> </ul>"},{"location":"design/execute/#status-flags","title":"Status Flags","text":"<ul> <li><code>zero_o</code>: Indicates if the result is zero.</li> <li><code>slt_o</code>: Set if the first operand is less than the second (signed).</li> <li><code>sltu_o</code>: Set if the first operand is less than the second (unsigned).</li> </ul>"},{"location":"design/fetch/","title":"Instruction Fetch Stage","text":"<p>The Instruction Fetch (IF) stage is a critical part of the TCore pipeline, responsible for initiating the execution cycle by fetching instructions from memory. This stage integrates several essential modules that ensure smooth and efficient operation. Here is an overview of its core functionalities:</p>"},{"location":"design/fetch/#core-functionalities","title":"Core Functionalities","text":"<ol> <li>Branch Prediction: </li> <li> <p>At the beginning of the fetch stage, branch prediction logic attempts to predict the outcome of branches (taken or not taken). This prediction minimizes stalls in the pipeline and ensures the processor continues executing instructions without waiting for the branch resolution.</p> </li> <li> <p>Program Counter (PC) Generation:</p> </li> <li> <p>The Program Counter (PC) is updated dynamically based on the branch prediction output and the previous instruction's execution. This mechanism ensures that the correct instruction address is computed efficiently.</p> </li> <li> <p>Instruction Fetching:</p> </li> <li> <p>Instructions are fetched from the instruction cache or main memory using the computed program counter. The fetched instructions are then passed on for further processing in subsequent stages.</p> </li> <li> <p>Compressed Instruction Decoding:</p> </li> <li> <p>If the fetched instruction is a compressed (16-bit) RISC-V instruction, it is expanded into its full 32-bit equivalent. This step ensures compatibility with the standard execution pipeline and resolves alignment issues introduced by compressed instructions.</p> </li> <li> <p>Return Address Stack (RAS):</p> </li> <li>The Return Address Stack (RAS) is a specialized structure used to store and retrieve return addresses for function calls. During the fetch stage, when a function call instruction is encountered, the return address is pushed onto the RAS. Conversely, when a return instruction is processed, the address is popped from the stack, ensuring accurate and efficient control flow handling. The RAS significantly improves performance by reducing branch mispredictions related to function calls and returns.</li> </ol>"},{"location":"design/fetch/#diagram","title":"Diagram","text":""},{"location":"design/fetch/#ports","title":"Ports","text":"Port name Direction Type clk_i input rst_ni input stall_i input fe_stall_i input lx_ires_i input ilowX_res_t pc_target_i input [XLEN-1:0] spec_hit_i input spec_o output predict_info_t lx_ireq_o output ilowX_req_t pc_o output [XLEN-1:0] pc4_o output [XLEN-1:0] pc2_o output [XLEN-1:0] inst_o output [XLEN-1:0] imiss_stall_o output is_comp_o output"},{"location":"design/fetch/#stall_i-signal-description","title":"<code>stall_i</code> Signal Description","text":"<p>The <code>stall_i</code> signal serves as a critical control mechanism to temporarily halt the pipeline under specific circumstances. This signal is asserted in the following scenarios:</p> <ol> <li> <p>Cache Misses:    When an instruction or data request results in a cache miss, the pipeline must pause until the required data is fetched from the memory hierarchy.</p> </li> <li> <p>Multi-Cycle ALU Operations:    During arithmetic or logic operations that require multiple clock cycles to complete, such as complex multiplications or divisions, the pipeline is stalled to prevent data hazards and ensure proper synchronization.</p> </li> </ol> <p>By introducing controlled halts, the <code>stall_i</code> signal ensures that dependencies are resolved and the pipeline operates reliably without proceeding to the next stage prematurely.</p>"},{"location":"design/fetch/#fe_stall_i","title":"<code>fe_stall_i</code>","text":"<p>The <code>fe_stall_i</code> signal is used to indicate a pipeline stall caused by load dependencies. This occurs in classic scenarios where an instruction depends on the result of a prior load operation. To prevent data hazards, the pipeline is temporarily stalled until the required data is available for subsequent instructions.</p> <p>This signal plays a crucial role in maintaining data consistency and ensuring that dependent instructions are executed correctly without introducing errors into the pipeline.</p>"},{"location":"design/fetch/#lx_ires_i","title":"<code>lx_ires_i</code>","text":"<p>The <code>lx_ires_i</code> signal represents the response port for lower hierarchy memory when handling instruction cache misses. When an instruction request results in a cache miss, this signal facilitates the retrieval of the required instruction data from the lower memory hierarchy.</p>"},{"location":"design/fetch/#pc_target_i","title":"<code>pc_target_i</code>","text":"<p>The <code>pc_target_i</code> signal carries the next Program Counter (PC) value determined during the execution stage. This value is typically computed based on branch decisions and directs the pipeline to the appropriate instruction address.</p>"},{"location":"design/fetch/#spec_hit_i","title":"<code>spec_hit_i</code>","text":"<p>The <code>spec_hit_i</code> signal indicates whether the branch prediction made earlier was correct. A high signal value confirms that the prediction was accurate, helping maintain pipeline efficiency by avoiding unnecessary stalls or flushes.</p>"},{"location":"design/fetch/#spec_o","title":"<code>spec_o</code>","text":"<p>The <code>spec_o</code> signal provides branch prediction information to the pipeline. It communicates whether a branch was taken and, if so, the target Program Counter (PC) value. This ensures smooth instruction flow during branching scenarios.</p>"},{"location":"design/fetch/#pc_o-pc2_o-pc4_o","title":"<code>pc_o</code>, <code>pc2_o</code>, <code>pc4_o</code>","text":"<p>These signals provide sequential Program Counter (PC) values to the pipeline: - <code>pc_o</code>: The current Program Counter value. - <code>pc2_o</code>: The current Program Counter plus 2, typically for compressed instruction alignment. - <code>pc4_o</code>: The current Program Counter plus 4, for the next sequential 32-bit instruction.</p>"},{"location":"design/fetch/#inst_o","title":"<code>inst_o</code>","text":"<p>The <code>inst_o</code> signal carries the fetched instruction to the Decode stage. This ensures that the pipeline receives the necessary instruction data for further processing.</p>"},{"location":"design/fetch/#is_comp_o","title":"<code>is_comp_o</code>","text":"<p>The <code>is_comp_o</code> signal indicates whether the fetched instruction is a compressed (16-bit) instruction. This information is essential for ensuring proper handling and alignment within the pipeline.</p>"},{"location":"design/fetch/#instantiations","title":"Instantiations","text":"<ul> <li>ipma: pma</li> <li>gray_align_buffer: gray_align_buffer</li> <li>icache: icache</li> <li>compressed_decoder: riscv_compressed_decoder</li> <li>branch_prediction</li> </ul>"},{"location":"design/fetch/#pma-module-physical-memory-attributes","title":"PMA Module: Physical Memory Attributes","text":""},{"location":"design/fetch/#diagram_1","title":"Diagram","text":"<p>The PMA (Physical Memory Attributes) module is a key component in the TCore RISC-V Processor, designed to manage memory access and define specific behaviors for different memory regions. Below is an overview of its functionality and implementation details.</p>"},{"location":"design/fetch/#key-features","title":"Key Features","text":"<ol> <li>Memory Region Classification:</li> <li> <p>The PMA module classifies memory regions based on predefined attributes such as cached/uncached and memory region type.</p> </li> <li> <p>Configurable Regions:</p> </li> <li>Supports multiple memory regions, with attributes defined in a structured format.</li> </ol>"},{"location":"design/fetch/#inputs-and-outputs","title":"Inputs and Outputs","text":"<ul> <li>Inputs:</li> <li><code>addr_i</code>: The input address to be checked against the defined memory attributes.</li> <li>Outputs:</li> <li><code>uncached_o</code>: Indicates whether the address belongs to an uncached region.</li> <li><code>memregion_o</code>: Indicates whether the address is part of a recognized memory region.</li> </ul>"},{"location":"design/fetch/#internal-data-structure","title":"Internal Data Structure","text":"<ul> <li>The module uses a structured type, <code>pma_t</code>, to represent each memory region. This includes:</li> <li><code>addr</code>: Base address of the memory region.</li> <li><code>mask</code>: Bitmask to define the size of the memory region.</li> <li><code>uncached</code>: Specifies if the region is uncached.</li> <li><code>memregion</code>: Specifies if the address belongs to a valid memory region.</li> </ul>"},{"location":"design/fetch/#memory-region-definitions","title":"Memory Region Definitions","text":"<p>The following regions are defined in the PMA module:</p> Region Address Range Cached Memory Region Memregion <code>0x4000_0000</code> - <code>0x400F_FFFF</code> Yes Yes UART <code>0x2000_0000</code> - <code>0x2000_000F</code> Yes No Timer <code>0x3000_0000</code> - <code>0x3000_0007</code> No Yes"},{"location":"design/fetch/#logical-flow","title":"Logical Flow","text":"<ol> <li>Region Matching:</li> <li>Each incoming address is compared with predefined regions using the <code>addr</code> and <code>mask</code> fields.</li> <li> <p>Matching is performed with bitwise AND operations to efficiently check membership.</p> </li> <li> <p>Output Determination:</p> </li> <li>Based on the matching region, the outputs <code>uncached_o</code> and <code>memregion_o</code> are set accordingly.</li> </ol>"},{"location":"design/fetch/#use-cases","title":"Use Cases","text":"<ul> <li>Memory Management: Defines behaviors for different memory regions in the TCore pipeline.</li> <li>Peripheral Access: Ensures correct handling of UART and timer regions.</li> </ul>"},{"location":"design/fetch/#gray-align-buffer-instruction-alignment-for-compressed-instructions","title":"Gray Align Buffer: Instruction Alignment for Compressed Instructions","text":""},{"location":"design/fetch/#diagram_2","title":"Diagram","text":"<p>The Gray Align Buffer is a specialized module in the TCore RISC-V processor designed to handle instruction alignment, particularly for compressed instruction support. By leveraging a structure inspired by the Gray cache architecture, this module ensures seamless execution of compressed and uncompressed instructions.</p>"},{"location":"design/fetch/#key-features_1","title":"Key Features","text":"<ol> <li>Support for Compressed Instructions:</li> <li>Handles RISC-V compressed (16-bit) and uncompressed (32-bit) instructions effectively.</li> <li> <p>Ensures proper alignment for seamless decoding and execution in the pipeline.</p> </li> <li> <p>Even and Odd Buffering:</p> </li> <li>Separates instruction handling into even and odd parcels for optimized storage and retrieval.</li> <li> <p>Manages unaligned instructions efficiently, ensuring compatibility across different instruction formats.</p> </li> <li> <p>Conflict Resolution:</p> </li> <li>Resolves cache misses and overlaps dynamically using stateful logic for hit/miss detection.</li> </ol>"},{"location":"design/fetch/#internal-structure","title":"Internal Structure","text":"<ul> <li>Buffer Organization:</li> <li>The buffer is divided into even and odd storage regions, optimized for efficient access.</li> <li> <p>Each buffer entry includes:</p> <ul> <li>Validity bit</li> <li>Address tags</li> <li>Data parcels for instruction storage</li> </ul> </li> <li> <p>Tag Matching and Addressing:</p> </li> <li>Uses tags and masks to identify and locate instructions within the buffer.</li> <li>Efficiently manages unaligned addresses using modular calculations.</li> </ul>"},{"location":"design/fetch/#use-cases_1","title":"Use Cases","text":"<ul> <li>Compressed Instruction Handling:</li> <li>Essential for RISC-V cores supporting compressed instructions.</li> <li>Cache Optimization:</li> <li>Provides seamless alignment and retrieval, reducing pipeline stalls.</li> </ul>"},{"location":"design/fetch/#icache-fully-configurable-instruction-cache","title":"ICache: Fully Configurable Instruction Cache","text":""},{"location":"design/fetch/#diagram_3","title":"Diagram","text":"<p>The ICache (Instruction Cache) module is a critical component of the TCore RISC-V processor, designed to optimize instruction fetching by reducing memory access latency and improving overall pipeline efficiency. Its configurable nature makes it adaptable for various system requirements.</p>"},{"location":"design/fetch/#key-features_2","title":"Key Features","text":"<ol> <li>Fully Configurable Design:</li> <li> <p>Parameters such as cache size, block size, associativity, and word length are fully customizable, allowing the cache to be tailored to specific application needs.</p> </li> <li> <p>Multi-Way Associativity:</p> </li> <li> <p>Supports multiple associativity levels, enabling flexible memory access patterns and enhanced performance.</p> </li> <li> <p>Cache Management:</p> </li> <li>Includes logic for handling cache hits, misses, and replacement policies.</li> <li>Utilizes a pseudo-LRU (Least Recently Used) algorithm for efficient block replacement.</li> </ol>"},{"location":"design/fetch/#logical-flow_1","title":"Logical Flow","text":"<ol> <li>Instruction Fetch Request:</li> <li>Receives fetch requests from the pipeline.</li> <li> <p>Determines whether the requested instruction block is present in the cache.</p> </li> <li> <p>Hit/Miss Detection:</p> </li> <li>On a hit, retrieves the instruction block directly from the cache.</li> <li> <p>On a miss, forwards the request to lower memory and updates the cache upon data retrieval.</p> </li> <li> <p>Cache Update:</p> </li> <li>Updates tag and data arrays with the fetched block from lower memory.</li> <li>Maintains LRU state for future replacement decisions.</li> </ol>"},{"location":"design/fetch/#compressed-decoder-instruction-expansion-for-risc-v","title":"Compressed Decoder: Instruction Expansion for RISC-V","text":""},{"location":"design/fetch/#diagram_4","title":"Diagram","text":"<p>The Compressed Decoder module is responsible for expanding RISC-V compressed (16-bit) instructions into their full 32-bit equivalents. This process ensures compatibility with the standard execution pipeline and seamless handling of mixed instruction formats.</p>"},{"location":"design/fetch/#key-role","title":"Key Role","text":"<ul> <li>Instruction Expansion:</li> <li>Decodes and converts compressed instructions into 32-bit instructions.</li> </ul>"},{"location":"design/fetch/#branch-prediction-enhancing-pipeline-efficiency","title":"Branch Prediction: Enhancing Pipeline Efficiency","text":""},{"location":"design/fetch/#diagram_5","title":"Diagram","text":"<p>The Branch Prediction modules in the TCore RISC-V processor are designed to improve pipeline efficiency by minimizing branch-related stalls and ensuring smoother execution. Various branch prediction techniques are parametrically supported, each optimized for specific scenarios.</p>"},{"location":"design/fetch/#supported-branch-predictors","title":"Supported Branch Predictors","text":""},{"location":"design/fetch/#1-2-bit-dynamic-predictor","title":"1. 2-bit Dynamic Predictor","text":"<ul> <li>Overview: Utilizes a finite state machine (FSM) with four states (weak/strong taken, weak/strong not-taken) to dynamically predict branch outcomes based on past behavior.</li> <li>Advantages:</li> <li>Adapts to branch patterns over time.</li> <li>Balances accuracy and resource efficiency.</li> <li>Use Case: General-purpose pipelines with mixed branch behavior.</li> </ul>"},{"location":"design/fetch/#2-signed-branch-prediction","title":"2. Signed Branch Prediction","text":"<ul> <li>Overview: Incorporates signed-unsigned differentiation in branch prediction. Separate FSMs track prediction states for signed and unsigned branches.</li> <li>Advantages:</li> <li>Enhances prediction accuracy for signed and unsigned conditional branches.</li> <li>Reduces mispredictions in workloads with mixed signed/unsigned branching.</li> <li>Use Case: Workloads with diverse branching conditions.</li> </ul>"},{"location":"design/fetch/#3-forward-always-taken-backward-not-taken-predictor","title":"3. Forward Always-Taken, Backward Not-Taken Predictor","text":"<ul> <li>Overview: Predicts forward branches as always taken and backward branches as not taken. This static approach leverages the typical behavior of loops and forward jumps.</li> <li>Advantages:</li> <li>Minimal hardware overhead.</li> <li>Effective for loop-heavy workloads.</li> <li>Use Case: Embedded systems or applications with predictable branch patterns.</li> </ul>"},{"location":"design/fetch/#4-global-history-based-predictor-gshare","title":"4. Global History-Based Predictor (GShare)","text":"<ul> <li>Overview: Combines a Global History Register (GHR) with a Pattern History Table (PHT) to correlate global branch history with outcomes.</li> <li>Advantages:</li> <li>High accuracy for complex branch patterns.</li> <li>Utilizes global context for prediction.</li> <li>Use Case: High-performance pipelines with intricate branching behavior.</li> </ul>"},{"location":"design/memory/","title":"Memory Stage Documentation","text":"<p>The Memory Stage in the TCore RISC-V Processor handles interactions with memory and peripherals, including data reads and writes. It integrates cache mechanisms and memory-mapped I/O to support efficient and accurate data operations.</p>"},{"location":"design/memory/#key-functionalities","title":"Key Functionalities","text":"<ol> <li>Memory Access:</li> <li>Handles read and write requests for data memory.</li> <li> <p>Supports different data sizes (byte, halfword, word) with sign extension for loads.</p> </li> <li> <p>Data Cache Integration:</p> </li> <li>Implements a write-back, fully configurable data cache to reduce memory latency.</li> <li> <p>Handles cache misses and manages data consistency with lower-level memory.</p> </li> <li> <p>Peripheral Access:</p> </li> <li> <p>Supports memory-mapped I/O for peripherals like UART.</p> </li> <li> <p>Pipeline Integration:</p> </li> <li>Interfaces with the Execute and Writeback stages to ensure correct data flow.</li> </ol>"},{"location":"design/memory/#module-composition","title":"Module Composition","text":""},{"location":"design/memory/#1-data-cache","title":"1. Data Cache","text":"<ul> <li>Functionality: Caches data for faster memory access.</li> <li>Features:</li> <li>Write-back policy to reduce write latency.</li> <li>Configurable size and associativity.</li> <li>Replacement policies managed via PLRU.</li> </ul>"},{"location":"design/memory/#2-peripheral-interface","title":"2. Peripheral Interface","text":"<ul> <li>Functionality: Interfaces with memory-mapped peripherals (e.g., UART).</li> </ul>"},{"location":"design/memory/#3-address-permissions","title":"3. Address Permissions","text":"<ul> <li>Functionality: Determines memory regions and permissions.</li> </ul>"},{"location":"design/memory/#memory-access-logic","title":"Memory Access Logic","text":"<ul> <li>Read Handling:</li> <li>Supports byte, halfword, and word accesses.</li> <li>Handles sign extension for load instructions.</li> <li>Write Handling:</li> <li>Manages write data alignment based on address and data size.</li> <li>Cache Miss Handling:</li> <li>Requests data from lower-level memory on a cache miss.</li> </ul>"},{"location":"design/memory/#peripheral-access-logic","title":"Peripheral Access Logic","text":"<ul> <li>Integrates with peripherals using memory-mapped addresses.</li> <li>Controls UART operations for communication.</li> </ul>"},{"location":"design/overview/","title":"Processor Core: TCore Introduction","text":"<p>TCore is a custom RISC-V processor core supporting the RV32I, M, and C extensions. Designed with a balance of simplicity and flexibility, TCore offers unique features tailored to address common challenges in processor design. Below is a detailed introduction to its architecture and capabilities:</p>"},{"location":"design/overview/#key-features-and-innovations","title":"Key Features and Innovations","text":"<ul> <li> <p>Parametric Cache Design:   TCore features fully parametric and straightforward caches. To address alignment issues with compressed instructions, a Gray buffer system inspired by Gray\u2019s Cache architecture has been integrated.</p> </li> <li> <p>Branch Prediction:   Both static and dynamic branch prediction options are available as configurable parameters. This provides flexibility based on performance requirements and use cases.</p> </li> <li> <p>Pipeline Design:   TCore utilizes a 5-stage pipeline. Register files operate on the positive clock edge, enabling 3-stage data forwarding from Writeback, Memory, and Decode stages. This setup efficiently resolves data dependencies.</p> </li> <li> <p>Multiplication Algorithms:   The ALU supports multiple multiplication algorithms, including Wallace and Dadda trees, configurable via parameters. These algorithms are generated using a higher-level language, C++, for improved maintainability. Additionally, sequential multiplication is available as an alternative for specific use cases.</p> </li> <li> <p>Division Algorithm:   A classic long division approach is implemented. Larger multipliers required for optimized cycle count have been excluded to maintain simplicity and resource efficiency.</p> </li> </ul>"},{"location":"design/overview/#memory-and-peripheral-access","title":"Memory and Peripheral Access","text":"<ul> <li> <p>Memory Stage:   The Memory stage handles both data cache operations and peripheral access. A simple PMA (Physical Memory Attributes) module, as specified in the RISC-V spec, has been implemented for peripheral handling.</p> </li> <li> <p>Peripheral Communication:   Currently, the system does not utilize a bus for peripheral communication. However, future updates may introduce bus integration. The sole peripheral supported at this stage is a UART, with plans to expand support to additional peripherals in future revisions.</p> </li> <li> <p>Writeback Stage:   The Writeback stage is optional and can be parametrically included or excluded based on design requirements.</p> </li> </ul>"},{"location":"design/overview/#advanced-features","title":"Advanced Features","text":"<ul> <li> <p>Return Address Stack (RAS):   A RISC-V compliant RAS structure has been implemented to enhance performance.</p> </li> <li> <p>Cache Hierarchy:   While Level 1 caches are currently implemented, the data cache has been designed with Level 2 compatibility in mind for future scalability.</p> </li> </ul> <p>This introduction outlines TCore's innovative approach to processor design, balancing RISC-V compliance with custom enhancements. For more details, visit the GitHub repository.</p>"},{"location":"design/writeback/","title":"Writeback Stage Documentation","text":"<p>The Writeback Stage in the TCore RISC-V Processor finalizes the execution of instructions by writing results back to the register file or preparing data for further processing. It is the last stage in the pipeline, ensuring that computation results are stored correctly for subsequent use.</p>"},{"location":"design/writeback/#key-functionalities","title":"Key Functionalities","text":"<ol> <li>Result Selection:</li> <li>Determines the source of data to be written back to the register file.</li> <li> <p>Handles different data sources, such as ALU results, memory data, or program counter increments.</p> </li> <li> <p>Register Writeback:</p> </li> <li>Writes the selected data to the destination register in the register file.</li> <li>Ensures that write operations are disabled during pipeline stalls to prevent corruption.</li> </ol>"},{"location":"design/writeback/#module-composition","title":"Module Composition","text":""},{"location":"design/writeback/#1-result-multiplexer","title":"1. Result Multiplexer","text":"<ul> <li>Functionality: Selects the appropriate result to write back based on control signals.</li> <li>Inputs:</li> <li><code>data_sel_i</code>: Control signal for selecting the data source.</li> <li><code>alu_result_i</code>: Result from the Execute stage.</li> <li><code>read_data_i</code>: Data loaded from memory.</li> <li><code>pc2_i</code>, <code>pc4_i</code>: Incremented program counter values.</li> <li><code>is_comp_i</code>: Indicates compressed instruction format.</li> <li>Outputs:</li> <li><code>wb_data_o</code>: Final writeback data.</li> </ul>"}]}